{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d93d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "BERT_PATH = \".\"\n",
    "\n",
    "data_dir = Path('./AI4Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "61ffcb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train NBs: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 232.40it/s]\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 1\n",
    "\n",
    "\n",
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "\n",
    "paths_train = list((data_dir / 'train').glob('*.json'))[10:20]\n",
    "notebooks_train = [\n",
    "    read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n",
    "]\n",
    "df = (\n",
    "    pd.concat(notebooks_train)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ")\n",
    "df.source = df.source.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4e1486c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huynh\\AppData\\Local\\Temp\\ipykernel_22840\\2875427560.py:1: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  df_orders = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "df_orders = pd.read_csv(\n",
    "    data_dir / 'train_orders.csv',\n",
    "    index_col='id',\n",
    "    squeeze=True,\n",
    ").str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "92312426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7aac4b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_ = df_orders.to_frame().join(\n",
    "    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n",
    "    how='right',\n",
    ")\n",
    "\n",
    "ranks = {}\n",
    "for id_, cell_order, cell_id in df_orders_.itertuples():\n",
    "    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n",
    "\n",
    "df_ranks = (\n",
    "    pd.DataFrame\n",
    "    .from_dict(ranks, orient='index')\n",
    "    .rename_axis('id')\n",
    "    .apply(pd.Series.explode)\n",
    "    .set_index('cell_id', append=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c09aee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ba4cb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().merge(df_ranks, on=[\"id\", \"cell_id\"]).merge(df_ancestors, on=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1fcfca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "# import fasttext\n",
    "\n",
    "re_sc_ch = re.compile(r'\\P{L}+')\n",
    "re_sg_ch = re.compile(r' +\\p{L} +')\n",
    "re_sg_ch_st = re.compile(r'^\\p{L} +')\n",
    "re_mul_sp =  re.compile(r' +')\n",
    "re_pre_b = re.compile(r'^b +')\n",
    "\n",
    "def preprocess_text(document):\n",
    "        # Remove all the special characters\n",
    "        document = re_sc_ch.sub(' ', str(document))\n",
    "\n",
    "        # remove all single characters\n",
    "        document = re_sg_ch.sub(' ', document)\n",
    "\n",
    "        # Remove single characters from the start\n",
    "        document = re_sg_ch_st.sub(' ', document)\n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        document = re_mul_sp.sub(' ', document)\n",
    "\n",
    "        # Removing prefixed 'b'\n",
    "        document =re_pre_b.sub('', document)\n",
    "\n",
    "        return document\n",
    "\n",
    "    \n",
    "def preprocess_df(df):\n",
    "    \"\"\"\n",
    "    This function is for processing sorce of notebook\n",
    "    returns preprocessed dataframe\n",
    "    \"\"\"\n",
    "    return [preprocess_text(message) for message in df.source]\n",
    "\n",
    "df.source = df.source.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "567a4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained('./Model/Pre-trained/tokenizer')\n",
    "#model = AutoModelWithLMHead.from_pretrained('./Model/Pre-trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1edc436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplet(df, mode='train'):\n",
    "    triplets = []\n",
    "    ids = df.id.unique()\n",
    "    random_drop = np.random.random(size=10000)>0.9\n",
    "    count = 0\n",
    "\n",
    "    for id, df_tmp in tqdm(df.groupby('id')):\n",
    "        df_tmp_markdown = df_tmp[df_tmp['cell_type']=='markdown']\n",
    "\n",
    "        df_tmp_code = df_tmp[df_tmp['cell_type']=='code']\n",
    "        df_tmp_code_rank = df_tmp_code['rank'].values\n",
    "        df_tmp_code_cell_id = df_tmp_code['cell_id'].values\n",
    "\n",
    "        for cell_id, rank in df_tmp_markdown[['cell_id', 'rank']].values:\n",
    "            labels = np.array([(r==(rank+1)) for r in df_tmp_code_rank]).astype('int')\n",
    "\n",
    "            for cid, label in zip(df_tmp_code_cell_id, labels):\n",
    "                count += 1\n",
    "                if label==1:\n",
    "                    triplets.append( [cell_id, cid, label] )\n",
    "                    # triplets.append( [cid, cell_id, label] )\n",
    "                elif mode == 'test':\n",
    "                    triplets.append( [cell_id, cid, label] )\n",
    "                    # triplets.append( [cid, cell_id, label] )\n",
    "                elif random_drop[count%10000]:\n",
    "                    triplets.append( [cell_id, cid, label] )\n",
    "                    # triplets.append( [cid, cell_id, label] )\n",
    "\n",
    "    return triplets\n",
    "\n",
    "#triplets = generate_triplet(df, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0eedba91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10389"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3e806bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "MAX_LEN = 128\n",
    "    \n",
    "class MarkdownModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        self.distill_bert = AutoModel.from_pretrained(\"./Model\")\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.top = torch.nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        x = self.distill_bert(ids, mask)[0]\n",
    "        x = self.dropout(x)\n",
    "        x = self.top(x[:, 0, :])\n",
    "        x = torch.sigmoid(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d5bcdc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cellid_source = dict(zip(df['cell_id'].values, df['source'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fca30ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "\n",
    "class MarkdownDataset(Dataset):\n",
    "    def __init__(self, df, max_len, mode='train'):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"./Model/tokenizer\")\n",
    "        self.mode=mode\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df[index]\n",
    "        label = row[-1]\n",
    "        txt = dict_cellid_source[row[0]] + '[SEP]' + dict_cellid_source[row[1]]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            txt,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = torch.LongTensor(inputs['input_ids'])\n",
    "        mask = torch.LongTensor(inputs['attention_mask'])\n",
    "        return ids, mask, torch.FloatTensor([label])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "val_ds = MarkdownDataset(triplets, max_len=MAX_LEN, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d6038d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 128 \n",
    "#NW = 8\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=BS*2, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "92b4b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader, mode='train'):\n",
    "    model.eval()\n",
    "    tbar = tqdm(val_loader, file=sys.stdout) \n",
    "    preds = np.zeros(len(val_loader.dataset), dtype='float32')\n",
    "    labels = []\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "            pred = model(inputs[0], inputs[1]).detach().cpu().numpy().ravel()\n",
    "            preds[count:count+len(pred)] = pred\n",
    "            count += len(pred)\n",
    "            if mode=='train':\n",
    "                labels.append(target.detach().cpu().numpy().ravel())\n",
    "    if mode=='test':\n",
    "        return preds\n",
    "    else:\n",
    "        return np.concatenate(labels), np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a815cf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./Model were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./Model and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:15<00:00,  2.56it/s]\n"
     ]
    }
   ],
   "source": [
    "model = MarkdownModel()\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load('./my_model/First/my_own_model_21.bin'))\n",
    "y_test = validate(model, val_loader, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3272cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_copy = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a82eecc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10389"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b5d7fbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 416.57it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_vals = []\n",
    "count = 0\n",
    "for id, df_tmp in tqdm(df.groupby('id')):\n",
    "    df_tmp_mark = df_tmp[df_tmp['cell_type']=='markdown']\n",
    "    df_tmp_code = df_tmp[df_tmp['cell_type']!='markdown']\n",
    "    df_tmp_code_rank = df_tmp_code['rank'].rank().values\n",
    "    N_code = len(df_tmp_code_rank)\n",
    "    N_mark = len(df_tmp_mark)\n",
    "\n",
    "    preds_tmp = preds_copy[count:count+N_mark * N_code]\n",
    "    count += N_mark + N_code\n",
    "\n",
    "    for i in range(N_mark):\n",
    "        pred = preds_tmp[i*N_code:i*N_code+N_code] \n",
    "\n",
    "        softmax = np.exp((pred-np.mean(pred)) *20)/np.sum(np.exp((pred-np.mean(pred)) *20)) \n",
    "\n",
    "        rank = np.sum(softmax * df_tmp_code_rank)\n",
    "        pred_vals.append(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3356c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"cell_type\"] == \"markdown\", \"pred\"] = pred_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b81100a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "997c2fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect\n",
    "\n",
    "\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):\n",
    "        j = bisect(sorted_so_far, u)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0\n",
    "    total_2max = 0  # twice the maximum possible inversions across all instances\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d2f4659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [_p.split() for _p in sub_df['cell_order']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "944c5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [list(df_orders.loc[x]) for x in sub_df['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9e3d133b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4022510087067318"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_tau(y, p) \n",
    "#0.5901620303153493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31d4b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kendall_tau(y, p) #21\n",
    "#0.46545454545454545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b726c6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>bbdeb43f</td>\n",
       "      <td>code</td>\n",
       "      <td>this python environment comes with many helpful analytics libraries installed it is defined by the kaggle python do...</td>\n",
       "      <td>2</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>fd65ce23</td>\n",
       "      <td>code</td>\n",
       "      <td>pip install scikit allel</td>\n",
       "      <td>4</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>9f08dd38</td>\n",
       "      <td>code</td>\n",
       "      <td>import allel allel version</td>\n",
       "      <td>5</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>8601e3b0</td>\n",
       "      <td>code</td>\n",
       "      <td>callset allel read vcf input end als end als genomics data answerals subset annovar hg anno and geno no intergenic ...</td>\n",
       "      <td>7</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>1ad2d212</td>\n",
       "      <td>code</td>\n",
       "      <td>sorted callset keys</td>\n",
       "      <td>10</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>296862c5</td>\n",
       "      <td>code</td>\n",
       "      <td>callset samples</td>\n",
       "      <td>12</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>ac95ae9c</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np np version</td>\n",
       "      <td>13</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>8d2df64a</td>\n",
       "      <td>code</td>\n",
       "      <td>pip install zarr</td>\n",
       "      <td>14</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>a07f8cf0</td>\n",
       "      <td>code</td>\n",
       "      <td>import zarr zarr version</td>\n",
       "      <td>15</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>7527cb70</td>\n",
       "      <td>code</td>\n",
       "      <td>pip install numcodecs</td>\n",
       "      <td>16</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>f3deebf8</td>\n",
       "      <td>code</td>\n",
       "      <td>import numcodecs numcodecs version</td>\n",
       "      <td>17</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>2c01e760</td>\n",
       "      <td>code</td>\n",
       "      <td>vcf path input end als end als genomics data answerals subset annovar hg anno and geno no intergenic vcf ls lh vcf p...</td>\n",
       "      <td>19</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>f27b5e59</td>\n",
       "      <td>code</td>\n",
       "      <td>zarr path input end als end als genomics data answerals subset annovar hg anno and geno no intergenic vcf</td>\n",
       "      <td>21</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>dee9baa0</td>\n",
       "      <td>code</td>\n",
       "      <td>the original snippet used data from chromosome end als didn mention any chromossome in the file trying to make it w...</td>\n",
       "      <td>22</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>c1f3c3f1</td>\n",
       "      <td>code</td>\n",
       "      <td>allel vcf to zarr vcf path zarr path group fields log sys stdout overwrite true</td>\n",
       "      <td>23</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>d0b1b18a</td>\n",
       "      <td>code</td>\n",
       "      <td>callset zarr open group zarr path mode callset tree expand true</td>\n",
       "      <td>26</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>8435366f</td>\n",
       "      <td>code</td>\n",
       "      <td>gt zarr callset calldata gt gt zarr info</td>\n",
       "      <td>27</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>0319e373</td>\n",
       "      <td>code</td>\n",
       "      <td>pos allel sortedindex callset variants pos pos</td>\n",
       "      <td>29</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>294aa174</td>\n",
       "      <td>code</td>\n",
       "      <td>loc region pos locate range loc region</td>\n",
       "      <td>30</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>9416121e</td>\n",
       "      <td>code</td>\n",
       "      <td>gt region allel genotypearray gt zarr loc region gt region</td>\n",
       "      <td>31</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>ffc38261</td>\n",
       "      <td>code</td>\n",
       "      <td>multi allelic callset variants multi allelic multi allelic</td>\n",
       "      <td>33</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>f3123de4</td>\n",
       "      <td>code</td>\n",
       "      <td>gt allel genotypearray gt zarr gt</td>\n",
       "      <td>35</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>ee4874a9</td>\n",
       "      <td>code</td>\n",
       "      <td>gt variant selection gt compress loc variant selection axis gt variant selection</td>\n",
       "      <td>37</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>2ea24302</td>\n",
       "      <td>code</td>\n",
       "      <td>gt dask allel genotypedaskarray gt zarr gt dask</td>\n",
       "      <td>39</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>e2633290</td>\n",
       "      <td>code</td>\n",
       "      <td>gt variant selection gt dask compress loc variant selection axis compute gt variant selection</td>\n",
       "      <td>41</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>df2b46e0</td>\n",
       "      <td>markdown</td>\n",
       "      <td>that snippet above took so long more than minutes to read vcf and is consuming my ram then commented it</td>\n",
       "      <td>8</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>5e8c349b</td>\n",
       "      <td>markdown</td>\n",
       "      <td>extract data and convert to zarr format use the vcf to zarr function from scikit allel that conversion will make li...</td>\n",
       "      <td>20</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>d04d2f63</td>\n",
       "      <td>markdown</td>\n",
       "      <td>hope to learn little bit how to work with vcf files scikit allel and bioinformatics</td>\n",
       "      <td>42</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>41741968</td>\n",
       "      <td>markdown</td>\n",
       "      <td>code by alistair miles http alimanfoo github io selecting variants html</td>\n",
       "      <td>3</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>a2a0f190</td>\n",
       "      <td>markdown</td>\n",
       "      <td>the samples array contains sample identifiers extracted from the header line in the vcf file</td>\n",
       "      <td>11</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>f254f6fd</td>\n",
       "      <td>markdown</td>\n",
       "      <td>loading data for gene</td>\n",
       "      <td>28</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>ac0e5da7</td>\n",
       "      <td>markdown</td>\n",
       "      <td>the callset object returned by read vcf is python dictionary dict it contains several numpy arrays each of which ca...</td>\n",
       "      <td>9</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>d3a1e7e5</td>\n",
       "      <td>markdown</td>\n",
       "      <td>after fspathexistnotdir path exists but is not directory everything went wrong maybe anyone can fix it</td>\n",
       "      <td>24</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>8de85e7b</td>\n",
       "      <td>markdown</td>\n",
       "      <td>use dask if data is larger and or your computer doesn have much ram</td>\n",
       "      <td>38</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>ad0f92c8</td>\n",
       "      <td>markdown</td>\n",
       "      <td>https image slidesharecdn com karenfent enabling biobankscale genomic processing with spark sql jpg cb slideshare net</td>\n",
       "      <td>0</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>002e57d8</td>\n",
       "      <td>markdown</td>\n",
       "      <td>extract genotypes for the selection</td>\n",
       "      <td>36</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>a9584e4f</td>\n",
       "      <td>markdown</td>\n",
       "      <td>extract data from vcf</td>\n",
       "      <td>18</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>e3359ac5</td>\n",
       "      <td>markdown</td>\n",
       "      <td>open the zarr data</td>\n",
       "      <td>25</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>27d29d73</td>\n",
       "      <td>markdown</td>\n",
       "      <td>filtering variants</td>\n",
       "      <td>32</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>43957940</td>\n",
       "      <td>markdown</td>\n",
       "      <td>extract genotype data for these variants</td>\n",
       "      <td>34</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>ce72e39f</td>\n",
       "      <td>markdown</td>\n",
       "      <td>variant call format vcf</td>\n",
       "      <td>1</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>a77d13be</td>\n",
       "      <td>markdown</td>\n",
       "      <td>apply the selection using almost the same syntax except that when working via dask we need to call the compute meth...</td>\n",
       "      <td>40</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>000624d747afd3</td>\n",
       "      <td>587ae493</td>\n",
       "      <td>markdown</td>\n",
       "      <td>start with the scikit allel function read vcf</td>\n",
       "      <td>6</td>\n",
       "      <td>55fbe5b5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id   cell_id cell_type                                                                                                                   source rank ancestor_id  \\\n",
       "0   000624d747afd3  bbdeb43f      code   this python environment comes with many helpful analytics libraries installed it is defined by the kaggle python do...    2    55fbe5b5   \n",
       "1   000624d747afd3  fd65ce23      code                                                                                                 pip install scikit allel    4    55fbe5b5   \n",
       "2   000624d747afd3  9f08dd38      code                                                                                              import allel allel version     5    55fbe5b5   \n",
       "3   000624d747afd3  8601e3b0      code   callset allel read vcf input end als end als genomics data answerals subset annovar hg anno and geno no intergenic ...    7    55fbe5b5   \n",
       "4   000624d747afd3  1ad2d212      code                                                                                                     sorted callset keys    10    55fbe5b5   \n",
       "5   000624d747afd3  296862c5      code                                                                                                         callset samples    12    55fbe5b5   \n",
       "6   000624d747afd3  ac95ae9c      code                                                                                           import numpy as np np version    13    55fbe5b5   \n",
       "7   000624d747afd3  8d2df64a      code                                                                                                         pip install zarr   14    55fbe5b5   \n",
       "8   000624d747afd3  a07f8cf0      code                                                                                                import zarr zarr version    15    55fbe5b5   \n",
       "9   000624d747afd3  7527cb70      code                                                                                                    pip install numcodecs   16    55fbe5b5   \n",
       "10  000624d747afd3  f3deebf8      code                                                                                      import numcodecs numcodecs version    17    55fbe5b5   \n",
       "11  000624d747afd3  2c01e760      code  vcf path input end als end als genomics data answerals subset annovar hg anno and geno no intergenic vcf ls lh vcf p...   19    55fbe5b5   \n",
       "12  000624d747afd3  f27b5e59      code               zarr path input end als end als genomics data answerals subset annovar hg anno and geno no intergenic vcf    21    55fbe5b5   \n",
       "13  000624d747afd3  dee9baa0      code   the original snippet used data from chromosome end als didn mention any chromossome in the file trying to make it w...   22    55fbe5b5   \n",
       "14  000624d747afd3  c1f3c3f1      code                                         allel vcf to zarr vcf path zarr path group fields log sys stdout overwrite true    23    55fbe5b5   \n",
       "15  000624d747afd3  d0b1b18a      code                                                         callset zarr open group zarr path mode callset tree expand true    26    55fbe5b5   \n",
       "16  000624d747afd3  8435366f      code                                                                                 gt zarr callset calldata gt gt zarr info   27    55fbe5b5   \n",
       "17  000624d747afd3  0319e373      code                                                                           pos allel sortedindex callset variants pos pos   29    55fbe5b5   \n",
       "18  000624d747afd3  294aa174      code                                                                                   loc region pos locate range loc region   30    55fbe5b5   \n",
       "19  000624d747afd3  9416121e      code                                                               gt region allel genotypearray gt zarr loc region gt region   31    55fbe5b5   \n",
       "20  000624d747afd3  ffc38261      code                                                               multi allelic callset variants multi allelic multi allelic   33    55fbe5b5   \n",
       "21  000624d747afd3  f3123de4      code                                                                                        gt allel genotypearray gt zarr gt   35    55fbe5b5   \n",
       "22  000624d747afd3  ee4874a9      code                                         gt variant selection gt compress loc variant selection axis gt variant selection   37    55fbe5b5   \n",
       "23  000624d747afd3  2ea24302      code                                                                          gt dask allel genotypedaskarray gt zarr gt dask   39    55fbe5b5   \n",
       "24  000624d747afd3  e2633290      code                            gt variant selection gt dask compress loc variant selection axis compute gt variant selection   41    55fbe5b5   \n",
       "25  000624d747afd3  df2b46e0  markdown                 that snippet above took so long more than minutes to read vcf and is consuming my ram then commented it     8    55fbe5b5   \n",
       "26  000624d747afd3  5e8c349b  markdown   extract data and convert to zarr format use the vcf to zarr function from scikit allel that conversion will make li...   20    55fbe5b5   \n",
       "27  000624d747afd3  d04d2f63  markdown                                     hope to learn little bit how to work with vcf files scikit allel and bioinformatics    42    55fbe5b5   \n",
       "28  000624d747afd3  41741968  markdown                                                  code by alistair miles http alimanfoo github io selecting variants html    3    55fbe5b5   \n",
       "29  000624d747afd3  a2a0f190  markdown                            the samples array contains sample identifiers extracted from the header line in the vcf file    11    55fbe5b5   \n",
       "30  000624d747afd3  f254f6fd  markdown                                                                                                    loading data for gene   28    55fbe5b5   \n",
       "31  000624d747afd3  ac0e5da7  markdown   the callset object returned by read vcf is python dictionary dict it contains several numpy arrays each of which ca...    9    55fbe5b5   \n",
       "32  000624d747afd3  d3a1e7e5  markdown                  after fspathexistnotdir path exists but is not directory everything went wrong maybe anyone can fix it    24    55fbe5b5   \n",
       "33  000624d747afd3  8de85e7b  markdown                                                      use dask if data is larger and or your computer doesn have much ram   38    55fbe5b5   \n",
       "34  000624d747afd3  ad0f92c8  markdown    https image slidesharecdn com karenfent enabling biobankscale genomic processing with spark sql jpg cb slideshare net    0    55fbe5b5   \n",
       "35  000624d747afd3  002e57d8  markdown                                                                                      extract genotypes for the selection   36    55fbe5b5   \n",
       "36  000624d747afd3  a9584e4f  markdown                                                                                                    extract data from vcf   18    55fbe5b5   \n",
       "37  000624d747afd3  e3359ac5  markdown                                                                                                      open the zarr data    25    55fbe5b5   \n",
       "38  000624d747afd3  27d29d73  markdown                                                                                                       filtering variants   32    55fbe5b5   \n",
       "39  000624d747afd3  43957940  markdown                                                                                 extract genotype data for these variants   34    55fbe5b5   \n",
       "40  000624d747afd3  ce72e39f  markdown                                                                                                 variant call format vcf     1    55fbe5b5   \n",
       "41  000624d747afd3  a77d13be  markdown   apply the selection using almost the same syntax except that when working via dask we need to call the compute meth...   40    55fbe5b5   \n",
       "42  000624d747afd3  587ae493  markdown                                                                           start with the scikit allel function read vcf     6    55fbe5b5   \n",
       "\n",
       "   parent_id  pred  \n",
       "0        NaN   NaN  \n",
       "1        NaN   NaN  \n",
       "2        NaN   NaN  \n",
       "3        NaN   NaN  \n",
       "4        NaN   NaN  \n",
       "5        NaN   NaN  \n",
       "6        NaN   NaN  \n",
       "7        NaN   NaN  \n",
       "8        NaN   NaN  \n",
       "9        NaN   NaN  \n",
       "10       NaN   NaN  \n",
       "11       NaN   NaN  \n",
       "12       NaN   NaN  \n",
       "13       NaN   NaN  \n",
       "14       NaN   NaN  \n",
       "15       NaN   NaN  \n",
       "16       NaN   NaN  \n",
       "17       NaN   NaN  \n",
       "18       NaN   NaN  \n",
       "19       NaN   NaN  \n",
       "20       NaN   NaN  \n",
       "21       NaN   NaN  \n",
       "22       NaN   NaN  \n",
       "23       NaN   NaN  \n",
       "24       NaN   NaN  \n",
       "25       NaN  13.0  \n",
       "26       NaN  13.0  \n",
       "27       NaN  13.0  \n",
       "28       NaN  13.0  \n",
       "29       NaN  13.0  \n",
       "30       NaN  13.0  \n",
       "31       NaN  13.0  \n",
       "32       NaN  13.0  \n",
       "33       NaN  13.0  \n",
       "34       NaN  13.0  \n",
       "35       NaN  13.0  \n",
       "36       NaN  13.0  \n",
       "37       NaN  13.0  \n",
       "38       NaN  13.0  \n",
       "39       NaN  13.0  \n",
       "40       NaN  13.0  \n",
       "41       NaN  13.0  \n",
       "42       NaN  13.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837136f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
