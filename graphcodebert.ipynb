{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b4f3d8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-08T07:27:26.159183Z",
     "iopub.status.busy": "2022-08-08T07:27:26.158488Z",
     "iopub.status.idle": "2022-08-08T07:27:28.075701Z",
     "shell.execute_reply": "2022-08-08T07:27:28.074386Z"
    },
    "papermill": {
     "duration": 1.926483,
     "end_time": "2022-08-08T07:27:28.079346",
     "exception": false,
     "start_time": "2022-08-08T07:27:26.152863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os, sys\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "model_path = \"../input/kagglemodels/GraphCodeBert\"\n",
    "ckpt_path = \"../input/kaggle-models/model.bin\"\n",
    "tokenizer_path = \"../input/kagglemodels/GraphCodeBert/tokenizer\"\n",
    "\n",
    "data_dir = Path('../input/AI4Code')\n",
    "total_max_len = 512\n",
    "TOKENIZERS_PARALLELISM=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4307ba5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T07:27:28.092808Z",
     "iopub.status.busy": "2022-08-08T07:27:28.092145Z",
     "iopub.status.idle": "2022-08-08T07:27:28.211065Z",
     "shell.execute_reply": "2022-08-08T07:27:28.209550Z"
    },
    "papermill": {
     "duration": 0.129295,
     "end_time": "2022-08-08T07:27:28.214757",
     "exception": false,
     "start_time": "2022-08-08T07:27:28.085462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 66.21it/s]\n"
     ]
    }
   ],
   "source": [
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "df = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ").reset_index()\n",
    "df[\"rank\"] = df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "df[\"pred\"] = df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "df.source = df.source.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188586d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T07:27:28.228258Z",
     "iopub.status.busy": "2022-08-08T07:27:28.227880Z",
     "iopub.status.idle": "2022-08-08T07:27:28.242719Z",
     "shell.execute_reply": "2022-08-08T07:27:28.241683Z"
    },
    "papermill": {
     "duration": 0.023732,
     "end_time": "2022-08-08T07:27:28.244909",
     "exception": false,
     "start_time": "2022-08-08T07:27:28.221177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_code(cell):\n",
    "    return str(cell).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "\n",
    "def sample_cells(cells, n):\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if n >= len(cells):\n",
    "        return [cell[:200] for cell in cells]\n",
    "    else:\n",
    "        results = []\n",
    "        step = len(cells) / n\n",
    "        idx = 0\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            results.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        assert cells[0] in results\n",
    "        if cells[-1] not in results:\n",
    "            results[-1] = cells[-1]\n",
    "        return results\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = dict()\n",
    "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
    "    for idx, sub_df in tqdm(df.groupby(\"id\")):\n",
    "        features[idx] = dict()\n",
    "        total_md = sub_df[sub_df.cell_type == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df.cell_type == \"code\"]\n",
    "        total_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df.source.values, 20)\n",
    "        features[idx][\"total_code\"] = total_code\n",
    "        features[idx][\"total_md\"] = total_md\n",
    "        features[idx][\"codes\"] = codes\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4e31d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T07:27:28.255048Z",
     "iopub.status.busy": "2022-08-08T07:27:28.254760Z",
     "iopub.status.idle": "2022-08-08T07:27:28.342775Z",
     "shell.execute_reply": "2022-08-08T07:27:28.341517Z"
    },
    "papermill": {
     "duration": 0.09634,
     "end_time": "2022-08-08T07:27:28.345683",
     "exception": false,
     "start_time": "2022-08-08T07:27:28.249343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 498.08it/s]\n"
     ]
    }
   ],
   "source": [
    "test_fts = get_features(df)\n",
    "\n",
    "import regex as re\n",
    "\n",
    "def preprocess_text_sc(document):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(document))\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    return document\n",
    "\n",
    "df.source = df.source.apply(preprocess_text_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07688030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T07:27:28.359388Z",
     "iopub.status.busy": "2022-08-08T07:27:28.358993Z",
     "iopub.status.idle": "2022-08-08T07:27:28.832273Z",
     "shell.execute_reply": "2022-08-08T07:27:28.831176Z"
    },
    "papermill": {
     "duration": 0.483239,
     "end_time": "2022-08-08T07:27:28.834887",
     "exception": false,
     "start_time": "2022-08-08T07:27:28.351648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super(MarkdownModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        self.top = nn.Linear(769, 1)\n",
    "        \n",
    "    def forward(self, ids, mask, fts):\n",
    "        x = self.model(ids, mask)[0]\n",
    "        x = self.top(torch.cat((x[:, 0, :], fts),1))\n",
    "        return x\n",
    "\n",
    "class MarkdownDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer_path, total_max_len, md_max_len, fts):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.md_max_len = md_max_len\n",
    "        self.total_max_len = total_max_len  # maxlen allowed by model config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "        self.fts = fts\n",
    "        self.dict_code_encode = self.code_encodes(self.df, self.fts)\n",
    "        \n",
    "    \n",
    "    def code_encodes(self, df, fts):\n",
    "        list_index = self.df.id.unique()\n",
    "        dict_code_encode = {}\n",
    "        for idx in list_index:\n",
    "            code_inputs = self.tokenizer.batch_encode_plus(\n",
    "                [str(x) for x in self.fts[idx][\"codes\"]],\n",
    "                add_special_tokens=True,\n",
    "                max_length=23,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True\n",
    "            )\n",
    "            dict_code_encode[idx] = code_inputs\n",
    "        return dict_code_encode\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row.source,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.md_max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        code_inputs = self.dict_code_encode[row.id]\n",
    "        n_md = self.fts[row.id][\"total_md\"]\n",
    "        n_code = self.fts[row.id][\"total_md\"]\n",
    "        if n_md + n_code == 0:\n",
    "            fts = torch.FloatTensor([0])\n",
    "        else:\n",
    "            fts = torch.FloatTensor([n_md / (n_md + n_code)])\n",
    "\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1])\n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(ids))\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "\n",
    "        return ids, mask, fts, torch.FloatTensor([row.pct_rank])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e833281e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T07:27:28.843091Z",
     "iopub.status.busy": "2022-08-08T07:27:28.842807Z",
     "iopub.status.idle": "2022-08-08T07:27:28.854108Z",
     "shell.execute_reply": "2022-08-08T07:27:28.853187Z"
    },
    "papermill": {
     "duration": 0.017784,
     "end_time": "2022-08-08T07:27:28.856253",
     "exception": false,
     "start_time": "2022-08-08T07:27:28.838469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "\n",
    "            pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "def predict(model_path, ckpt_path, tokenizer_path):\n",
    "    model = MarkdownModel(model_path)\n",
    "    model = model.to('cuda:0')\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location='cuda:0'))\n",
    "    BS = 32\n",
    "    NW = 8\n",
    "    MAX_LEN = 64\n",
    "    df[\"pct_rank\"] = 0\n",
    "    test_ds = MarkdownDataset(df[df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), \n",
    "                              md_max_len=64,\n",
    "                              tokenizer_path = tokenizer_path,\n",
    "                              total_max_len = total_max_len,\n",
    "                              fts=test_fts)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BS, \n",
    "                             shuffle=False,\n",
    "                             num_workers=NW,\n",
    "                             pin_memory=False,\n",
    "                             drop_last=False)\n",
    "    _, y_test = validate(model, test_loader)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33bcec1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T07:27:28.864120Z",
     "iopub.status.busy": "2022-08-08T07:27:28.863547Z",
     "iopub.status.idle": "2022-08-08T07:27:46.840129Z",
     "shell.execute_reply": "2022-08-08T07:27:46.838844Z"
    },
    "papermill": {
     "duration": 17.983219,
     "end_time": "2022-08-08T07:27:46.842681",
     "exception": false,
     "start_time": "2022-08-08T07:27:28.859462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "y_test = predict(model_path, ckpt_path, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fcd0e42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T07:27:46.854614Z",
     "iopub.status.busy": "2022-08-08T07:27:46.853597Z",
     "iopub.status.idle": "2022-08-08T07:27:46.876659Z",
     "shell.execute_reply": "2022-08-08T07:27:46.875608Z"
    },
    "papermill": {
     "duration": 0.031065,
     "end_time": "2022-08-08T07:27:46.879271",
     "exception": false,
     "start_time": "2022-08-08T07:27:46.848206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>0a226b6a ddfd239c 8cb8d28a c6cd22db 1372ae9b e25aa9bd 90ed07ab ba55e576 7f388a41 f9893819 2843a25a 39e937ec 06dbf8cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>23607d04 b7578789 aafc3d23 80e077ec bbff12d4 b190ebb4 d3f5c397 8ce62db4 584f6568 ed415c3c 89b1fdd2 322850af 35cd0771...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>eb293dfc 012c9d02 d22526d1 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                               cell_order\n",
       "0  0009d135ece78d     0a226b6a ddfd239c 8cb8d28a c6cd22db 1372ae9b e25aa9bd 90ed07ab ba55e576 7f388a41 f9893819 2843a25a 39e937ec 06dbf8cf\n",
       "1  0010483c12ba9b                                7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d\n",
       "2  0010a919d60e4f  23607d04 b7578789 aafc3d23 80e077ec bbff12d4 b190ebb4 d3f5c397 8ce62db4 584f6568 ed415c3c 89b1fdd2 322850af 35cd0771...\n",
       "3  0028856e09c5b7                                                                                      eb293dfc 012c9d02 d22526d1 3ae7ece3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.cell_type=='markdown', \"pred\"] = y_test\n",
    "sub_df = df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e413cb82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-08T07:27:46.889235Z",
     "iopub.status.busy": "2022-08-08T07:27:46.888849Z",
     "iopub.status.idle": "2022-08-08T07:27:46.896650Z",
     "shell.execute_reply": "2022-08-08T07:27:46.895771Z"
    },
    "papermill": {
     "duration": 0.015312,
     "end_time": "2022-08-08T07:27:46.898722",
     "exception": false,
     "start_time": "2022-08-08T07:27:46.883410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871cc04",
   "metadata": {
    "papermill": {
     "duration": 0.003702,
     "end_time": "2022-08-08T07:27:46.906282",
     "exception": false,
     "start_time": "2022-08-08T07:27:46.902580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.734661,
   "end_time": "2022-08-08T07:27:48.132366",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-08T07:27:18.397705",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
